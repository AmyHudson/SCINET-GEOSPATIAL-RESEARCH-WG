{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing on Ceres with Python and Dask\n",
    "(adapted from https://github.com/willirath/dask_jobqueue_workshop_materials)\n",
    "\n",
    "## Core Lessons\n",
    "\n",
    "- setting up SLURM clusters\n",
    "- scaling clusters\n",
    "- adaptive clusters\n",
    "- viewing Dask diagnostics\n",
    "\n",
    "This tutorial will demonstrate how to use Dask to manage compute jobs on a SLURM cluster (including setting up your SLURM compute cluster, scaling the cluster, and how to use an adaptive cluster to save compute resources for others). The tutorial will also explain how to access the Dask diagnostics dashboard to view the cluster working in real time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Pre-Tutorial Setup\n",
    "#### 1. Be able to login to the Ceres HPC \n",
    "\n",
    "   You should receive email instructions for logging in and setting up multifactor authentication when your SCINet account is approved. \n",
    "   Instructions can also be found in the [Ceres User Guide](https://scinet.usda.gov/guide/ceres/#logging-in-to-scinet) and the [Multifactor Authentication Guide](https://scinet.usda.gov/guide/multifactor/#authentication-on-your-computer-using-authy). \n",
    "   Contact the VRSC at scinet_vrsc@usda.gov if you have problems.\n",
    "    \n",
    "#### 2. Get a Github account \n",
    "    \n",
    "   If you don't already have a Github account, sign up for a free account at https://github.com/join.\n",
    "    \n",
    "#### 3. Software setup\n",
    "   \n",
    "   a. Install miniconda on your Ceres account. Experienced HPC users can go to https://docs.conda.io/en/latest/miniconda.html and install the latest version of miniconda either in your home directory or your project /KEEP directory, and then keep conda up to date using \"conda update conda\". \n",
    "   \n",
    "   Another option, which may be better for newer HPC users, is to load the miniconda module that is already installed on Ceres. The only downside is that it may be slightly outdated and you will have to load the module every time you want to use it. Follow the instructions in the [User-Installed Software of Ceres with Conda Guide](https://scinet.usda.gov/guide/conda/).\n",
    "    \n",
    "#### 4. Clone the tutorials repository from Github to your Ceres account\n",
    "   \n",
    "   go to the repository at xx\n",
    "   click \"Clone or Download\" and copy the http link to your clipboard\n",
    "   login to the Ceres HPC and navigate to where you want to copy the repository \n",
    "        **(where should this be run from, best practice? scratch?)**\n",
    "   issue the command: git clone paste-the-repository-link-here\n",
    "   \n",
    "#### 5. Activate the python environment for this tutorial\n",
    "   \n",
    "   Copy the python environment for this tutorial xx located at xx to your conda environments folder, which should be located wherever you installed conda then under xx/xx/xx.\n",
    "   Activate the python environment using \"xx\".\n",
    "\n",
    "#### 6. Open JupyterLab (or JupyterHub?) to execute the tutorials\n",
    "   follow the instructions at xx\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Estimate of $\\pi$\n",
    "\n",
    "This tutorial uses the Monte-Carlo estimate of $\\pi$ to demonstrate how Dask works.\n",
    "\n",
    "We want to estimate the number $\\pi$ using a [Monte-Carlo method](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods) exploiting that the area of a quarter circle of unit radius is $\\pi/4$ and that hence the probability of any randomly chosen point in a unit square to lie in a unit circle centerd at a corner of the unit square is $\\pi/4$ as well. \n",
    "\n",
    "So for N randomly chosen pairs $(x, y)$ with $x\\in[0, 1)$ and $y\\in[0, 1)$, we count the number $N_{circ}$ of pairs that also satisfy $(x^2 + y^2) < 1$ and estimate $\\pi \\approx 4 \\cdot N_{circ} / N$.\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif\" \n",
    "     width=\"50%\" \n",
    "     align=top\n",
    "     alt=\"PI monte-carlo estimate\">](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Slurm cluster\n",
    "\n",
    "We'll now use dask.distributed and dask_jobqueue packages to create a SLURM cluster. The SLURMCluster function can be interpreted as the settings/parameters for 1 SLURM job. Later, we can increase our compute power by \"scaling our cluster\", which means Dask will execute more than one SLURM job at a time for any given computation.\n",
    "\n",
    "**Here's a key to the dask_jobqueue.SLURMCluster inpute parameters in the code block below:**<br>\n",
    "\n",
    "**cores** = Number of logical cores per job. This will be divided among the processes/workers. Can't be more than the lowest number of logical cores per node in the queue you choose, see https://scinet.usda.gov/guide/ceres/#partitions-or-queues.\n",
    "   \n",
    "**processes** = Number of processes per job (also known as Dask \"workers\"). Can use 1 but more than 1 helps keep job running if cores/workers fail. The number of cores per worker will be cores/processes.\n",
    "\n",
    "**memory** =  Memory per job. This will be divided among the processes/workers. **need info on how to know max mem per node you can request** <br>\n",
    "queue = name of the ceres queue/partition (e.g. short, brief-low, debug, etc.)<br>\n",
    "walltime = time allowed for the compute to finish before timing out<br>\n",
    "local_directory = local spill location if the core memory is exceeded **(is this correct)**<br>\n",
    "log_directory = location to write the stdout and stderr files for each worker process. \n",
    "\n",
    "View additional parameters, methods, and attributes for [dask_jobqueue.SLURMCluster](https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import os\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=40,\n",
    "    processes=2,\n",
    "    memory=\"100GB\",\n",
    "    queue=\"short\",\n",
    "    walltime=\"00:10:00\",\n",
    "    log_directory=\"/project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only set up a cluster, we have not started any compute jobs or workers running yet. We can verify this by issuing the following command in our Ceres terminal:\n",
    "```\n",
    "squeue -u firstname.lastname\n",
    "```\n",
    "\n",
    "To see the job-script that will be used to start workers with the HPC SLURM scheduler use the method .job_script().\n",
    "\n",
    "Here's a key to the output of the cluster.job_script() command in the code block below:<br>\n",
    "-J = name of the job (this will appear in the \"Name\" column of the squeue information) \"dask-worker\" is the default value<br>\n",
    "-e and -o = name/location of the stdout and stderr files<br>\n",
    "-p = queue/partition name<br>\n",
    "-n = number of nodes<br>\n",
    "--cpus-per-task = number of cores (same as -N)<br>\n",
    "--mem = <br>\n",
    "-t = walltime<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks/dask-worker-%J.err\n",
      "#SBATCH -o /project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=40\n",
      "#SBATCH --mem=94G\n",
      "#SBATCH -t 00:10:00\n",
      "\n",
      "/home/kerrie.geil/software/miniconda3/envs/tutorial01/bin/python -m distributed.cli.dask_worker tcp://10.1.4.44:42667 --nthreads 20 --nprocs 2 --memory-limit 50.00GB --name name --nanny --death-timeout 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Next, we must initialize a Dask Client, which opens a line of communication between Dask workers (processes) and the SLURM scheduler by pointing to the address of the scheduler (tcp://10.1.8.84:41601). <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:42667</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:42667' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: So far we have only set up a cluster and initialized a client. We still have not started any compute jobs or workers (processes) running yet, as shown in the Cluster information output above. We can verify that no workers are running yet by issuing the squeue command again as we did previously or we could access the Dask Diagnostics Dashboard for even more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Dask diagnostics dashboard\n",
    "\n",
    "We will now take a look at the Dashboard to verify that there a no workers running in our cluster yet. Once we start computing, we will be able to use the Dashboard to see a visual representation of all the workers running.\n",
    "\n",
    "INSERT INSTRUCTIONS TO OPEN THE DASHBOARD either port forward or better, figure out how to get the Dask extension working in JupyterLab/Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the cluster to two nodes\n",
    "\n",
    "Let's start 4 workers (in 2 SLURM jobs). \n",
    "\n",
    "For the distiction between _workers_ and _jobs_, see [the Dask jobqueue docs](https://jobqueue.dask.org/en/latest/howitworks.html#workers-vs-jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:42667</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>240</li>\n",
       "  <li><b>Memory: </b>600.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:42667' processes=8 threads=160, memory=400.00 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scale(jobs=6)  # scale to 4 _workers_\n",
    "sleep(15)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .scale() method actually starts the workers (processes) running as shown in the Cluster information output above. A quick check of squeue will now show your workers as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Monte Carlo Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to compute $\\pi$ and another function to print out some info during the compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "def calc_pi_mc(size_in_bytes, chunksize_in_bytes=200e6):\n",
    "    \"\"\"Calculate PI using a Monte Carlo estimate.\"\"\"\n",
    "    \n",
    "    size = int(size_in_bytes / 8)\n",
    "    chunksize = int(chunksize_in_bytes / 8)\n",
    "    \n",
    "    xy = da.random.uniform(0, 1,\n",
    "                           size=(size / 2, 2),\n",
    "                           chunks=(chunksize / 2, 2))\n",
    "    \n",
    "    in_circle = ((xy ** 2).sum(axis=-1) < 1)\n",
    "    pi = 4 * in_circle.mean()\n",
    "\n",
    "    return pi\n",
    "\n",
    "def print_pi_stats(size, pi, time_delta, num_workers):\n",
    "    \"\"\"Print pi, calculate offset from true value, and print some stats.\"\"\"\n",
    "    print(f\"{size / 1e9} GB\\n\"\n",
    "          f\"\\tMC pi: {pi : 13.11f}\"\n",
    "          f\"\\tErr: {abs(pi - np.pi) : 10.3e}\\n\"\n",
    "          f\"\\tWorkers: {num_workers}\"\n",
    "          f\"\\t\\tTime: {time_delta : 7.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual calculations\n",
    "\n",
    "We loop over different volumes (1GB, 10GB, and 100GB) of double-precision random numbers and estimate $\\pi$ as described above. Note, we call the function with the .compute() method to start the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in (1e9 * n for n in (1, 10, 100)):\n",
    "    \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi, time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Cluster to twice its size\n",
    "\n",
    "We increase the number of workers by 2 and the re-run the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_workers = 2 * len(cluster.scheduler.workers)\n",
    "\n",
    "print(f\"Scaling from {len(cluster.scheduler.workers)} to {new_num_workers} workers.\")\n",
    "\n",
    "cluster.scale(new_num_workers)\n",
    "\n",
    "sleep(15)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run same experiments with doubled cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in (1e9 * n for n in (1, 10, 100)):\n",
    "    \n",
    "        \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi,\n",
    "                   time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Scaling the Cluster\n",
    "\n",
    "We want each calculation to take only a few seconds.  Dask will try to add more workers to the cluster when workloads are high and remove workers when idling.\n",
    "\n",
    "_**Watch** how the cluster will scale down to the minimum a few seconds after being made adaptive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = cluster.adapt(\n",
    "    minimum=4, maximum=100);\n",
    "\n",
    "sleep(4)  # Allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the calculation from above with larger work loads\n",
    "\n",
    "(And watch the dash board!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in (n * 1e9 for n in (1, 10, 100, 1000)):\n",
    "    \n",
    "    \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size, min(size / 1000, 500e6)).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi, time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))\n",
    "    \n",
    "    sleep(20)  # allow for scale-down time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete listing of software used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda list --explicit"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tutorial01]",
   "language": "python",
   "name": "conda-env-tutorial01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
