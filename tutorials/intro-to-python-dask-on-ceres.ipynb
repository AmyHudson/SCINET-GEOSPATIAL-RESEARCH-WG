{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing on Ceres with Python and Dask\n",
    "(adapted from https://github.com/willirath/dask_jobqueue_workshop_materials)\n",
    "\n",
    "## Core Lessons\n",
    "\n",
    "- setting up SLURM clusters\n",
    "- scaling clusters\n",
    "- adaptive clusters\n",
    "- viewing Dask diagnostics\n",
    "\n",
    "This tutorial will demonstrate how to use Dask to manage compute jobs on a SLURM cluster (including setting up your SLURM compute cluster, scaling the cluster, and how to use an adaptive cluster to save compute resources for others). The tutorial will also explain how to access the Dask diagnostics dashboard to view the cluster working in real time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Pre-Tutorial Setup\n",
    "#### 1. Be able to login to the Ceres HPC \n",
    "\n",
    "   You should receive email instructions for logging in and setting up multifactor authentication when your SCINet account is approved. \n",
    "   Instructions can also be found in the [Ceres User Guide](https://scinet.usda.gov/guide/ceres/#logging-in-to-scinet) and the [Multifactor Authentication Guide](https://scinet.usda.gov/guide/multifactor/#authentication-on-your-computer-using-authy). \n",
    "   Contact the VRSC at scinet_vrsc@usda.gov if you have problems.\n",
    "    \n",
    "#### 2. Get a Github account \n",
    "    \n",
    "   If you don't already have a Github account, sign up for a free account at https://github.com/join.\n",
    "    \n",
    "#### 3. Software setup\n",
    "   \n",
    "   a. Install miniconda on your Ceres account. Experienced HPC users can go to https://docs.conda.io/en/latest/miniconda.html and install the latest version of miniconda either in your home directory or your project /KEEP directory, and then keep conda up to date using \"conda update conda\". \n",
    "   \n",
    "   Another option, which may be better for newer HPC users, is to load the miniconda module that is already installed on Ceres. The only downside is that it may be slightly outdated and you will have to load the module every time you want to use it. Follow the instructions in the [User-Installed Software of Ceres with Conda Guide](https://scinet.usda.gov/guide/conda/).\n",
    "    \n",
    "#### 4. Clone the tutorials repository from Github to your Ceres account\n",
    "   \n",
    "   go to the repository at xx\n",
    "   click \"Clone or Download\" and copy the http link to your clipboard\n",
    "   login to the Ceres HPC and navigate to where you want to copy the repository \n",
    "   issue the command: git clone paste-the-repository-link-here\n",
    "   \n",
    "#### 5. Activate the python environment for this tutorial\n",
    "   \n",
    "   Copy the python environment for this tutorial xx located at xx to your conda environments folder, which should be located wherever you installed conda then under xx/xx/xx.\n",
    "   Activate the python environment using \"xx\".\n",
    "\n",
    "#### 6. Open JupyterLab (or JupyterHub?) to execute the tutorial\n",
    "   follow the instructions at xx\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Tutorial: Parallel Computing on Ceres with Python and Dask\n",
    "\n",
    "In this tutorial we will compute in parallel using Python's Dask package to communicate with the Ceres HPC SLURM job scheduler. \n",
    "\n",
    "SLURM (Simple Linux Utility for Resource Management) is a workload manager for HPC systems. From the [SLURM documentation](https://slurm.schedmd.com/quickstart.html), SLURM is \"an open source... cluster management and job scheduling system for large and small Linux clusters. As a cluster workload manager, SLURM has three key functions. First, it allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work. Second, it provides a framework for starting, executing, and monitoring work (normally a parallel job) on the set of allocated nodes. Finally, it arbitrates contention for resources by managing a queue of pending work.\"\n",
    "\n",
    "## Set up a SLURM Cluster with Dask\n",
    "\n",
    "The first step is to create a SLURM cluster using dask.distributed and dask_jobqueue packages. The SLURMCluster function can be interpreted as the settings/parameters for 1 SLURM compute job. Later, we can increase our compute power by \"scaling our cluster\", which means Dask will execute more than one SLURM job at a time for any given computation.\n",
    "<br><br>\n",
    "\n",
    "**Here's a key to the dask_jobqueue.SLURMCluster input parameters in the code block below:**\n",
    "\n",
    "**cores** = Number of logical cores per job. This will be divided among the processes/workers. Can't be more than the lowest number of logical cores per node in the queue you choose, see https://scinet.usda.gov/guide/ceres/#partitions-or-queues.\n",
    "   \n",
    "**processes** = Number of processes per job (also known as Dask \"workers\" or \"worker processes\"). Can use 1 but more than 1 helps keep your computations running if cores/workers fail. The number of cores per worker will be cores/processes.\n",
    "\n",
    "**memory** =  Memory per job. This will be divided among the processes/workers. **need info on how to know max mem per node you can request** \n",
    "\n",
    "**queue** = Name of the Ceres queue, a.k.a. partition (e.g. short, medium, long, long60, mem, longmem, mem768, debug, brief-low, scavenger, etc.).\n",
    "\n",
    "**walltime** = Time allowed before the job is timed out.\n",
    "\n",
    "**local_directory** = local spill location if the core memory is exceeded **(is this correct and what is the best practice location)**\n",
    "\n",
    "**log_directory** = Location to write the stdout and stderr files for each worker process. Simplest choice may be the directory you are running your code from. \n",
    "<br><br>\n",
    "\n",
    "You can view additional parameters, methods, and attributes in the Dask documentation for [dask_jobqueue.SLURMCluster](https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import os\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=40,\n",
    "    processes=2,\n",
    "    memory=\"100GB\",\n",
    "    queue=\"short\",\n",
    "    walltime=\"00:10:00\",\n",
    "    log_directory=\"/project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only set up a cluster, we have not started any compute jobs or workers running yet. We can verify this by issuing the following command in our Ceres terminal:\n",
    "```\n",
    "squeue -u firstname.lastname\n",
    "```\n",
    "\n",
    "To see the job script that will be used to start a SLURM job on the Ceres HPC use the method .job_script() as shown in the code block below.\n",
    "<br><br>\n",
    "\n",
    "**Here's a key to the output of the cluster.job_script() command below:**\n",
    "\n",
    "**-J** = Name of the job. This will appear in the \"Name\" column of the squeue output. \"dask-worker\" is the default value.\n",
    "\n",
    "**-e and -o** = Name/Location of the stdout and stderr files for each job. This comes from the SLURMCLuster \"log_directory\" parameter.\n",
    "\n",
    "**-p** = Name of the Ceres queue/partition. This comes from the SLURMCLuster \"queue\" parameter.\n",
    "\n",
    "**-n** = Number of nodes. **are we always limited to 1 node for the setup job? i got errors when putting more cores than 40**\n",
    "\n",
    "**--cpus-per-task** = Number of cores per job (same as -N). This comes from the SLURMCluster \"cores\" parameter.\n",
    "\n",
    "**--mem** = Memory per job. This comes from the SLURMCluster \"memory\" parameter. **how is this limited, e.g. 100GB request, 96GB granted**\n",
    "\n",
    "**-t** = Time allowed before the job is timed out. This comes from the SLURMCluster parameter \"walltime\".\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks/dask-worker-%J.err\n",
      "#SBATCH -o /project/geospatial_user_test_geil/dask_jobqueue_workshop_materials/notebooks/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=40\n",
      "#SBATCH --mem=94G\n",
      "#SBATCH -t 00:10:00\n",
      "\n",
      "/home/kerrie.geil/software/miniconda3/envs/tutorial01/bin/python -m distributed.cli.dask_worker tcp://10.1.4.44:44953 --nthreads 20 --nprocs 2 --memory-limit 50.00GB --name name --nanny --death-timeout 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Next, we must initialize a Dask Client, which opens a line of communication between Dask worker processes and the SLURM job scheduler by pointing to the address of the scheduler (tcp://10.1.8.84:41601).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:44953</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:44953' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: So far we have only set up a cluster and initialized a client. We still have not started any compute jobs running yet, as shown in the Cluster information output above. We can verify that no workers are running yet by issuing the squeue command in our Ceres terminal again as we did previously or we could access the Dask Diagnostics Dashboard for even more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Dask Diagnostics Dashboard\n",
    "\n",
    "We will now take a look at the Dashboard to verify that there a no workers running in our cluster yet. Once we start computing, we will be able to use the Dashboard to see a visual representation of all the workers running.\n",
    "\n",
    "INSERT INSTRUCTIONS TO OPEN THE DASHBOARD either port forward or better, figure out how to get the Dask extension working in JupyterLab/Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Cluster\n",
    "\n",
    "Now let's start multiple SLURM jobs computing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep   #time for timing how long our computations take, sleep for pausing while SLURM starts the requested jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:44953</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:44953' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.scale(jobs=3)  # scale to more jobs\n",
    "sleep(15)              # pause while SLURM starts up the jobs\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .scale() method actually starts the jobs running as shown in the Cluster information above. A quick check of squeue will now show your multiple jobs running as well.\n",
    "\n",
    "When we set up our original cluster (equivalent of 1 SLURM job) we requested 40 cores spread over 2 workers. When we scaled our cluster to 3 jobs we now have 40x3=120 cores spread over 2x3=6 workers, as shown above. Note: you can also scale your cluster by workers or memory as opposed to jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Estimate of $\\pi$\n",
    "\n",
    "Now we will use the [Monte-Carlo method of estimating $\\pi$](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods)  to demonstrate how Dask can execute parallel computations with the SLURM Cluster we've built and scaled.\n",
    "\n",
    "We estimate the number $\\pi$ by exploiting that the area of a quarter circle of unit radius is $\\pi/4$ and that hence the probability of any randomly chosen point in a unit square to lie in a unit circle centerd at a corner of the unit square is $\\pi/4$ as well. \n",
    "\n",
    "So for N randomly chosen pairs $(x, y)$ with $x\\in[0, 1)$ and $y\\in[0, 1)$, we count the number $N_{circ}$ of pairs that also satisfy $(x^2 + y^2) < 1$ and estimate $\\pi \\approx 4 \\cdot N_{circ} / N$.\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif\" \n",
    "     width=\"50%\" \n",
    "     align=top\n",
    "     alt=\"PI monte-carlo estimate\">](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Let's define a function to compute $\\pi$ and another function to print out some info during the compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "def calc_pi_mc(size_in_bytes, chunksize_in_bytes=200e6):  # is there a reason to choose this chunksize\n",
    "    \"\"\"Calculate PI using a Monte Carlo estimate.\"\"\"\n",
    "    \n",
    "    size = int(size_in_bytes / 8)      # size= no. of random numbers to generate (x & y vals), divide 8 bcz numpy float64 numbers generated by random.uniform use up 8 bytes\n",
    "    chunksize = int(chunksize_in_bytes / 8)\n",
    "    \n",
    "    xy = da.random.uniform(0, 1,                          # this generates a set of x and y value pairs on the interval [0,1) of type float64\n",
    "                           size=(size / 2, 2),            # divide 2 because we are generating an equal number of x and y values (to get our points)\n",
    "                           chunks=(chunksize / 2, 2))     # why would i need to divide the chunksize by 2 here???\n",
    "    \n",
    "    in_circle = ((xy ** 2).sum(axis=-1) < 1)     # a boolean array, True for points that fall inside the unit circle (x**2 + y**2 < 1)\n",
    "    pi = 4 * in_circle.mean()                    # mean= sum the number of True elements, divide by the total number of elements in the array\n",
    "\n",
    "    return pi\n",
    "\n",
    "def print_pi_stats(size, pi, time_delta, num_workers):\n",
    "    \"\"\"Print pi, calculate offset from true value, and print some stats.\"\"\"\n",
    "    print(f\"{size / 1e9} GB\\n\"\n",
    "          f\"\\tMC pi: {pi : 13.11f}\"\n",
    "          f\"\\tErr: {abs(pi - np.pi) : 10.3e}\\n\"\n",
    "          f\"\\tWorkers: {num_workers}\"\n",
    "          f\"\\t\\tTime: {time_delta : 7.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual calculations\n",
    "\n",
    "We loop over different volumes (1GB, 10GB, and 100GB) of double-precision random numbers (float64, 8 bytes each) and estimate $\\pi$ as described above. Note, we call the function with the .compute() method to start the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GB\n",
      "\tMC pi:  3.14183603200\tErr:  2.434e-04\n",
      "\tWorkers: 6\t\tTime:  30.786s\n",
      "10.0 GB\n",
      "\tMC pi:  3.14146808320\tErr:  1.246e-04\n",
      "\tWorkers: 6\t\tTime:   2.070s\n",
      "100.0 GB\n",
      "\tMC pi:  3.14158354624\tErr:  9.107e-06\n",
      "\tWorkers: 6\t\tTime:   9.549s\n"
     ]
    }
   ],
   "source": [
    "for size in (1e9 * n for n in (1, 10, 100)):\n",
    "    \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi, time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Cluster to Twice its Size and Re-run Same Experiments\n",
    "\n",
    "We increase the number of workers times 2 and the re-run the experiments. You could also double the size of the cluster by doubling the number of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling from 6 to 12 workers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:44953</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>120</li>\n",
       "  <li><b>Memory: </b>300.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:44953' processes=6 threads=120, memory=300.00 GB>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_num_workers = 2 * len(cluster.scheduler.workers)\n",
    "\n",
    "print(f\"Scaling from {len(cluster.scheduler.workers)} to {new_num_workers} workers.\")\n",
    "\n",
    "cluster.scale(new_num_workers)\n",
    "\n",
    "# the following commands all get you the same amount of compute resources as above\n",
    "#cluster.scale(12)               # same as code above. default parameter is workers. (original num workers was 6)\n",
    "#cluster.scale(jobs=6)           # can scale by number of jobs\n",
    "#cluster.scale(cores=240)        # can also scale by cores\n",
    "#cluster.scale(memory=600) double check this one\n",
    "\n",
    "sleep(15)\n",
    "client\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GB\n",
      "\tMC pi:  3.14164006400\tErr:  4.741e-05\n",
      "\tWorkers: 6\t\tTime:   1.148s\n",
      "10.0 GB\n",
      "\tMC pi:  3.14168450560\tErr:  9.185e-05\n",
      "\tWorkers: 6\t\tTime:   1.767s\n",
      "100.0 GB\n",
      "\tMC pi:  3.14160476352\tErr:  1.211e-05\n",
      "\tWorkers: 6\t\tTime:   9.344s\n"
     ]
    }
   ],
   "source": [
    "for size in (1e9 * n for n in (1, 10, 100)):\n",
    "    \n",
    "        \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi,\n",
    "                   time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Scaling the Cluster\n",
    "\n",
    "We want each calculation to take only a few seconds.  Dask will try to add more workers to the cluster when workloads are high and remove workers when idling.\n",
    "\n",
    "_**Watch** how the cluster will scale down to the minimum a few seconds after being made adaptive._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = cluster.adapt(\n",
    "    minimum_jobs=1, maximum_jobs=10);\n",
    "\n",
    "sleep(5)  # Allow for scale-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.1.4.44:44953</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.1.4.44:8787/status' target='_blank'>http://10.1.4.44:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>100.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.1.4.44:44953' processes=2 threads=40, memory=100.00 GB>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the calculation from above with larger work loads\n",
    "\n",
    "(And watch the dash board!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 GB\n",
      "\tMC pi:  3.14117248000\tErr:  4.202e-04\n",
      "\tWorkers: 2\t\tTime:   8.357s\n",
      "10.0 GB\n",
      "\tMC pi:  3.14160690560\tErr:  1.425e-05\n",
      "\tWorkers: 2\t\tTime:   7.455s\n",
      "100.0 GB\n",
      "\tMC pi:  3.14156686080\tErr:  2.579e-05\n",
      "\tWorkers: 2\t\tTime:  15.852s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - addresses should be strings or tuples, got None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/utils.py\", line 664, in log_errors\n",
      "    yield\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/scheduler.py\", line 2169, in remove_worker\n",
      "    address = self.coerce_address(address)\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/scheduler.py\", line 4883, in coerce_address\n",
      "    raise TypeError(\"addresses should be strings or tuples, got %r\" % (addr,))\n",
      "TypeError: addresses should be strings or tuples, got None\n",
      "distributed.core - ERROR - addresses should be strings or tuples, got None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/core.py\", line 399, in handle_comm\n",
      "    result = handler(comm, **msg)\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/scheduler.py\", line 2169, in remove_worker\n",
      "    address = self.coerce_address(address)\n",
      "  File \"/home/kerrie.geil/software/miniconda3/envs/tutorial01/lib/python3.7/site-packages/distributed/scheduler.py\", line 4883, in coerce_address\n",
      "    raise TypeError(\"addresses should be strings or tuples, got %r\" % (addr,))\n",
      "TypeError: addresses should be strings or tuples, got None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0 GB\n",
      "\tMC pi:  3.14158997408\tErr:  2.680e-06\n",
      "\tWorkers: 17\t\tTime:  143.407s\n"
     ]
    }
   ],
   "source": [
    "for size in (n * 1e9 for n in (1, 10, 100, 1000)):\n",
    "    \n",
    "    \n",
    "    start = time()\n",
    "    pi = calc_pi_mc(size, min(size / 1000, 500e6)).compute()\n",
    "    elaps = time() - start\n",
    "\n",
    "    print_pi_stats(size, pi, time_delta=elaps,\n",
    "                   num_workers=len(cluster.scheduler.workers))\n",
    "    \n",
    "    sleep(20)  # allow for scale-down time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete listing of software used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda list --explicit"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-tutorial01]",
   "language": "python",
   "name": "conda-env-miniconda3-tutorial01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
